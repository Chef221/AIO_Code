{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa20f2ae",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c135405",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Generative Pre-trained Transformer (GPT)\n",
    "- Large-scale training\n",
    "- Contextual understanding\n",
    "- Multiple use cases\n",
    "\n",
    "Hallucianation: 2 luận điểm cốt lõi về nguyên nhân gây ra ảo giác\n",
    "- Cơ chế dự đoán token (Token Prediction):\n",
    "    + Hiệu ứng quả cầu tuyết (Eror Cascading): mô hình dự đoán từ tiếp theo dựa trên xác\n",
    "suất có điều kiện\n",
    "    + Nếu mô hình mắc một lỗi nhỏ ở token thứ 10 (ví dụ chọn sai một giới từ hoặc một tính\n",
    "từ), token thứ 11 sẽ coi lỗi đó là 'sự thật' để dự đoán tiếp\n",
    "    + Càng về sau, ngữ cảnh càng bị lái đi xa khỏi ý định ban đầu, dẫn đến việc mô hình\n",
    "bịa ra các chi tiết để hợp lý hóa cái lỗi trước đó\n",
    "\n",
    "- Dữ liệu và nhãn (Data & Labelling):\n",
    "    + Đây là vấn đề thuộc quy trình Supervised Fine-Tuning và RLHF (Reinforcement Learning\n",
    "from Human Feedback)\n",
    "    + Sự sai lệch hành vi (Misalignment): Khi người gán nhãn đánh giá câu trả lời của AI,\n",
    "họ thường ưu tiên các câu trả lời trôi chảy, tự tin và đúng ngữ pháp hơn là tính xác thực\n",
    "    + Mô hình học được rằng: 'Bịa ra một câu trả lời nghe có vẻ chuyên gia sẽ được điểm \n",
    "cao hơn là trả lời 'Tôi không biết'. Đây là nguyên nhân chính dẫn đến việc AI nói sai nhưng\n",
    "với giọng điệu rất chắc chắn\n",
    "    + Nhiều dữ liệu nguồn: Internet chứa đầy thông tin mâu thuẫn, lỗi thời, sai lệch. Mô\n",
    "hình học tất cả những thứ này mà không có khả năng tự nhiên để phân biệt đâu là chân lý \n",
    "nếu không được tinh chỉnh kỹ\n",
    "\n",
    "- Nén dữ liệu có tổn hao (Lossy Compression) và Tham số ngẫu nhiên (Temperature):\n",
    "    + Nén dữ liệu: Mô hình không lưu trữ sự kiện như một cơ sở dữ liệu mà nó lưu trữ xác\n",
    "suất liên kết giữa các từ\n",
    "    + Khi hỏi một sự kiện hiếm, mô hình không có ký ức chính xác. Nó sẽ dùng các mẫu phổ\n",
    "biến của các bản tin để tái tạo lại một câu trả lời trông giống thật nhất => Hallucination\n",
    "    + Tính ngẫu nhiên: Mô hình đôi khi chọn những từ có xác suất thấp hơn (không phải từ tối \n",
    "ưu nhất). Việc chọn ngẫu nhiên đôi khi dẫn đén một hướng đi sai lệch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Language model meta-learning\n",
    "- Model develops a broad set of skills and pattern recognition abilities at training time\n",
    "- Uses those abilities at inference time to rapidly adapt to or recognize the desired task\n",
    "\n",
    "2. In-context Learning (ICL)\n",
    "- Using the text input as a form of task specification\n",
    "- Based on 'prompts' of the task and is then expected to complete further instance\n",
    "- Three settings for in-context learning\n",
    "    + Zero shot: The model predicts the answer given only a natural language description\n",
    "of the task. No gradient updates are performed\n",
    "    + One shot: In addition to the task description, the model sees a single example of \n",
    "the task. No gradient updates are performed\n",
    "    + Few shot: In addition to the task description, the model sees a few examples of the \n",
    "task. No gradient updates are performed\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
